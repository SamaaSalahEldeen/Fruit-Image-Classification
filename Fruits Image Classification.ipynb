{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7224591,"sourceType":"datasetVersion","datasetId":4182114}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tensorflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T23:31:57.119006Z","iopub.execute_input":"2023-12-19T23:31:57.119503Z","iopub.status.idle":"2023-12-19T23:32:09.290085Z","shell.execute_reply.started":"2023-12-19T23:31:57.119467Z","shell.execute_reply":"2023-12-19T23:32:09.288944Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.9.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.24.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (68.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.34.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras import preprocessing\nimport os\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.utils import to_categorical\nfrom scipy import ndimage\nfrom keras import models\nfrom keras import layers\nfrom keras.models import load_model\nfrom keras.models import save_model\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\nimport tensorflow as tf\n#from keras import legacy\nfrom keras.preprocessing import image\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:38:46.960661Z","iopub.execute_input":"2023-12-20T16:38:46.961049Z","iopub.status.idle":"2023-12-20T16:39:00.145766Z","shell.execute_reply.started":"2023-12-20T16:38:46.961017Z","shell.execute_reply":"2023-12-20T16:39:00.144819Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to preprocess the dataset\ndef preprocess_dataset(data):\n    data_resized = cv2.resize(data, (224, 224))    #resize\n    data_normalized = data_resized / 255.0         #normalize\n    return data_normalized\n\n\n# the train and validation datasets\npath = \"/kaggle/input/nn-dataset/dataset/dataset/train\"\ndef Train_data_preprocessing_(path):\n    image_generator=ImageDataGenerator(\n        rescale=1/255,               #Scales the pixel values to the range [0,1].\n        rotation_range=10,           #Randomly rotates images by up to 10 degrees.\n        width_shift_range=0.2,       #Randomly shifts images horizontally by up to 20% of the width.\n        height_shift_range=0.2,      #Randomly shifts images vertically by up to 20% of the width.\n        zoom_range=0.2,              # Randomly zooms into images by up to 20%.\n        horizontal_flip=True,\n        validation_split=0.2,)   #20% validation from the training set\n    train_dataset=image_generator.flow_from_directory(batch_size=32,directory=path,\n                                    shuffle=True,target_size=(224,224),subset=\"training\",class_mode='categorical')\n    test_dataset=image_generator.flow_from_directory(batch_size=32,directory=path,\n                                  shuffle=True,target_size=(224,224),subset=\"validation\",class_mode='categorical')\n    return train_dataset,test_dataset \n\ntrain,test=Train_data_preprocessing_(path)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:17.633923Z","iopub.execute_input":"2023-12-20T16:40:17.634857Z","iopub.status.idle":"2023-12-20T16:40:33.829351Z","shell.execute_reply.started":"2023-12-20T16:40:17.634822Z","shell.execute_reply":"2023-12-20T16:40:33.828308Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 7920 images belonging to 5 classes.\nFound 1980 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"#2\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))  # convolutional layer 32filter with window size 3*3 \nmodel.add(MaxPooling2D((2, 2)))           #reduces the spatial dimensions of the input data by maximum value from each block.\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten()) #This layer flattens the output from the previous layer into a 1D array. It prepares the data for the fully connected layers.\nmodel.add(Dense(256, activation='relu')) #A fully connected layer with 256 units and a ReLU activation function.\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))  \n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(\n    train,\n    epochs=10, \n    validation_data=test\n)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint('best_model2.h5', save_best_only=True)\n# Training\nmodel.fit(train, epochs=10, validation_data=test, callbacks=[early_stopping, model_checkpoint], verbose=1)\n\nmodel.save('model2.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T17:30:54.905414Z","iopub.execute_input":"2023-12-20T17:30:54.905886Z","iopub.status.idle":"2023-12-20T18:05:23.998567Z","shell.execute_reply.started":"2023-12-20T17:30:54.905852Z","shell.execute_reply":"2023-12-20T18:05:23.997686Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/10\n248/248 [==============================] - 138s 551ms/step - loss: 1.3875 - accuracy: 0.4130 - val_loss: 1.2437 - val_accuracy: 0.4722\nEpoch 2/10\n248/248 [==============================] - 137s 552ms/step - loss: 1.1219 - accuracy: 0.5327 - val_loss: 1.1822 - val_accuracy: 0.4960\nEpoch 3/10\n248/248 [==============================] - 137s 553ms/step - loss: 1.0332 - accuracy: 0.5818 - val_loss: 1.1149 - val_accuracy: 0.5394\nEpoch 4/10\n248/248 [==============================] - 137s 553ms/step - loss: 0.9840 - accuracy: 0.6044 - val_loss: 1.0628 - val_accuracy: 0.5591\nEpoch 5/10\n248/248 [==============================] - 137s 553ms/step - loss: 0.9380 - accuracy: 0.6280 - val_loss: 1.1186 - val_accuracy: 0.5444\nEpoch 6/10\n248/248 [==============================] - 138s 555ms/step - loss: 0.9171 - accuracy: 0.6391 - val_loss: 0.9841 - val_accuracy: 0.6081\nEpoch 7/10\n248/248 [==============================] - 140s 564ms/step - loss: 0.8860 - accuracy: 0.6549 - val_loss: 0.9881 - val_accuracy: 0.6182\nEpoch 8/10\n248/248 [==============================] - 137s 552ms/step - loss: 0.8724 - accuracy: 0.6663 - val_loss: 1.0225 - val_accuracy: 0.5955\nEpoch 9/10\n248/248 [==============================] - 138s 556ms/step - loss: 0.8531 - accuracy: 0.6785 - val_loss: 0.9640 - val_accuracy: 0.6207\nEpoch 10/10\n248/248 [==============================] - 137s 554ms/step - loss: 0.8288 - accuracy: 0.6845 - val_loss: 0.9913 - val_accuracy: 0.6253\nEpoch 1/10\n248/248 [==============================] - ETA: 0s - loss: 0.8233 - accuracy: 0.6883","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"248/248 [==============================] - 139s 560ms/step - loss: 0.8233 - accuracy: 0.6883 - val_loss: 0.9480 - val_accuracy: 0.6379\nEpoch 2/10\n248/248 [==============================] - 142s 572ms/step - loss: 0.8115 - accuracy: 0.6867 - val_loss: 0.9049 - val_accuracy: 0.6444\nEpoch 3/10\n248/248 [==============================] - 137s 553ms/step - loss: 0.7899 - accuracy: 0.7040 - val_loss: 0.9061 - val_accuracy: 0.6657\nEpoch 4/10\n248/248 [==============================] - 136s 549ms/step - loss: 0.7697 - accuracy: 0.7105 - val_loss: 0.9108 - val_accuracy: 0.6606\nEpoch 5/10\n248/248 [==============================] - 137s 554ms/step - loss: 0.7572 - accuracy: 0.7112 - val_loss: 0.9123 - val_accuracy: 0.6540\n","output_type":"stream"}]},{"cell_type":"code","source":"# Path to the test dataset\ntest_dataset_path = \"/kaggle/input/nn-dataset/dataset/dataset/test\"\n\ndef preprocess_test_dataset(test_dataset_path):\n    preprocessed_data = []   # To store preprocessed images\n    labels = []              # To store labels\n\n    test_images_paths = [os.path.join(test_dataset_path, filename) for filename in os.listdir(test_dataset_path) if\n                         filename.endswith(('.jpg', '.jpeg', '.png'))]   # Get paths of all images in the test dataset directory\n     #read the images\n    for image_path in test_images_paths:\n        image = cv2.imread(image_path)\n        if image is None:\n            print(f\"Error: Unable to read the image: {image_path}\")\n            continue\n\n        # Preprocess the  image\n        preprocessed_image = preprocess_dataset(image)\n        preprocessed_data.append(preprocessed_image)\n\n        # Extract label without file extension\n        labels.append(os.path.splitext(os.path.basename(image_path))[0])\n         # Convert the preprocessed data to a numpy array\n        preprocessed_data = np.array(preprocessed_data)\n        #shape handling\n        if len(preprocessed_data.shape) == 3:\n            preprocessed_data = preprocessed_data.reshape((-1, 224, 224, 3))\n\n    return preprocessed_data, labels\n\n# Modified test_images function\ndef test_images(test_dataset_path, model):\n    preprocessed_data, labels = preprocess_test_dataset(test_dataset_path)\n\n    if preprocessed_data.shape[0] == 0:\n        print(\"No valid images in the test dataset.\")\n        return\n    #make prediction\n    predictions = model.predict(preprocessed_data)\n    predicted_labels = np.argmax(predictions, axis=1) + 1\n\n    results = pd.DataFrame({'image_id': labels, 'label': predicted_labels})\n    print(results)\n\n    csv_file_path = 'predictmodel2.csv'\n    results.to_csv(csv_file_path, index=False)\n\n#load the model\nmodel2=load_model('model2.h5')\n# Set the path to the test dataset\ntest_dataset_path = \"/kaggle/input/nn-dataset/dataset/dataset/test\"\n\n# Test the images and save the results to a CSV file\ntest_images(test_dataset_path,model2)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T18:10:03.972710Z","iopub.execute_input":"2023-12-20T18:10:03.973080Z","iopub.status.idle":"2023-12-20T18:10:06.902790Z","shell.execute_reply.started":"2023-12-20T18:10:03.973052Z","shell.execute_reply":"2023-12-20T18:10:06.901197Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"4/4 [==============================] - 0s 76ms/step\n   image_id  label\n0      1266      3\n1      1862      4\n2       311      5\n3      3362      2\n4      3652      1\n..      ...    ...\n95     3813      1\n96      639      5\n97     3449      2\n98     1656      2\n99     1910      4\n\n[100 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n# Define the Transformer model\ndef build_transformer_model(input_shape=(224, 224, 3), num_classes=5):\n    inputs = layers.Input(shape=input_shape)\n\n    # Preprocessing layers\n    x = layers.Rescaling(scale=1.0 / 255)(inputs)     #scalling the input\n\n    # Transformer layers\n    backbone = tf.keras.applications.ResNet50(\n        include_top=False,     #only the base convolutional layer\n        weights='imagenet',  #from the model\n        input_tensor=x,  #specifies the input tensor for the model\n        pooling=None    #no global pooling will be applied by the ResNet50 model. The output will be the activation maps from the last convolutional layer.\n    )\n    x = backbone.output    #feature extractor from el backbone\n\n    # Classification head with modifications\n    x = layers.GlobalAveragePooling2D()(x)  #computes the spatial average of the entire feature map, reducing its spatial dimensions.\n    x = layers.Dense(512, activation='relu')(x) \n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n\n    # Create the model\n    model = Model(inputs=inputs, outputs=outputs)\n\n    # Compile the model with a learning rate schedule\n    def lr_schedule(epoch, lr):         \n        if epoch < 10:\n            return lr\n        else:\n            return lr * tf.math.exp(-0.1)\n\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\n\n    return model\n\n# Modify the train_alexnet function to train the Transformer model\ndef train_transformer(model, train_data, test_data, epochs=100):\n    # Define early stopping callback\n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=10,\n        restore_best_weights=True\n    )\n\n    # Define model checkpoint callback to save the best weights\n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        'transformer_best.h5',\n        save_best_only=True,\n        save_weights_only=True,\n        monitor='val_loss',\n        mode='min',\n        verbose=1\n    )\n\n    # Training\n    model.fit(train_data, epochs=epochs, validation_data=test_data, callbacks=[early_stopping, model_checkpoint], verbose=1)\n\n    return model\n\ninput_shape = (224, 224, 3)\nnum_classes = 5\n\n# Build and train the Transformer model\ntransformer_model = build_transformer_model(input_shape, num_classes)\ntrained_model = train_transformer(transformer_model, train, test, epochs=20)\ntrained_model.save('transformer2.h5')\n\n# Define the test_images function to test the Transformer model\ndef test_images(test_dataset_path, model):\n    preprocessed_data, labels = preprocess_test_dataset(test_dataset_path)\n\n    if preprocessed_data.shape[0] == 0:\n        print(\"No valid images in the test dataset.\")\n        return\n\n    predictions = model.predict(preprocessed_data)\n    predicted_labels = np.argmax(predictions, axis=1) + 1\n\n    results = pd.DataFrame({'image_id': labels, 'label': predicted_labels})\n    print(results)\n\n    csv_file_path = 'trans.csv'\n    results.to_csv(csv_file_path, index=False)\n\n# Load the trained model\ntransformer_model = tf.keras.models.load_model('transformer2.h5')\n\n# Set the path to the test dataset\ntest_dataset_path = \"/kaggle/input/nn-dataset/dataset/dataset/test\"\n\n# Test the images and save the results to a CSV file\ntest_images(test_dataset_path, transformer_model)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:06:44.564013Z","iopub.execute_input":"2023-12-20T22:06:44.564937Z","iopub.status.idle":"2023-12-20T22:56:13.131681Z","shell.execute_reply.started":"2023-12-20T22:06:44.564900Z","shell.execute_reply":"2023-12-20T22:56:13.130781Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Epoch 1/20\n248/248 [==============================] - ETA: 0s - loss: 2.0536 - accuracy: 0.2619\nEpoch 1: val_loss improved from inf to 1.69748, saving model to transformer_best.h5\n248/248 [==============================] - 186s 603ms/step - loss: 2.0536 - accuracy: 0.2619 - val_loss: 1.6975 - val_accuracy: 0.2000\nEpoch 2/20\n248/248 [==============================] - ETA: 0s - loss: 1.5147 - accuracy: 0.3524\nEpoch 2: val_loss did not improve from 1.69748\n248/248 [==============================] - 143s 574ms/step - loss: 1.5147 - accuracy: 0.3524 - val_loss: 1.8188 - val_accuracy: 0.2000\nEpoch 3/20\n248/248 [==============================] - ETA: 0s - loss: 1.3165 - accuracy: 0.4264\nEpoch 3: val_loss did not improve from 1.69748\n248/248 [==============================] - 142s 573ms/step - loss: 1.3165 - accuracy: 0.4264 - val_loss: 1.9218 - val_accuracy: 0.2000\nEpoch 4/20\n248/248 [==============================] - ETA: 0s - loss: 1.1310 - accuracy: 0.5449\nEpoch 4: val_loss did not improve from 1.69748\n248/248 [==============================] - 143s 574ms/step - loss: 1.1310 - accuracy: 0.5449 - val_loss: 2.1728 - val_accuracy: 0.2000\nEpoch 5/20\n248/248 [==============================] - ETA: 0s - loss: 1.0886 - accuracy: 0.5640\nEpoch 5: val_loss did not improve from 1.69748\n248/248 [==============================] - 144s 578ms/step - loss: 1.0886 - accuracy: 0.5640 - val_loss: 2.3151 - val_accuracy: 0.2000\nEpoch 6/20\n248/248 [==============================] - ETA: 0s - loss: 1.0404 - accuracy: 0.5900\nEpoch 6: val_loss did not improve from 1.69748\n248/248 [==============================] - 143s 576ms/step - loss: 1.0404 - accuracy: 0.5900 - val_loss: 2.7110 - val_accuracy: 0.2000\nEpoch 7/20\n135/248 [===============>..............] - ETA: 51s - loss: 1.0108 - accuracy: 0.6155Epoch 8/20\n248/248 [==============================] - ETA: 0s - loss: 1.0588 - accuracy: 0.5823\nEpoch 8: val_loss did not improve from 1.69748\n248/248 [==============================] - 143s 575ms/step - loss: 1.0588 - accuracy: 0.5823 - val_loss: 12.9594 - val_accuracy: 0.1929\nEpoch 9/20\n248/248 [==============================] - ETA: 0s - loss: 0.9720 - accuracy: 0.6342\nEpoch 9: val_loss did not improve from 1.69748\n248/248 [==============================] - 142s 572ms/step - loss: 0.9720 - accuracy: 0.6342 - val_loss: 3.7084 - val_accuracy: 0.2237\nEpoch 10/20\n248/248 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.5915\nEpoch 10: val_loss did not improve from 1.69748\n248/248 [==============================] - 142s 573ms/step - loss: 1.0340 - accuracy: 0.5915 - val_loss: 1.9539 - val_accuracy: 0.2581\nEpoch 11/20\n248/248 [==============================] - ETA: 0s - loss: 1.0097 - accuracy: 0.6104\nEpoch 11: val_loss improved from 1.69748 to 1.44494, saving model to transformer_best.h5\n248/248 [==============================] - 144s 580ms/step - loss: 1.0097 - accuracy: 0.6104 - val_loss: 1.4449 - val_accuracy: 0.3247\nEpoch 12/20\n248/248 [==============================] - ETA: 0s - loss: 0.9193 - accuracy: 0.6528\nEpoch 12: val_loss did not improve from 1.44494\n248/248 [==============================] - 142s 572ms/step - loss: 0.9193 - accuracy: 0.6528 - val_loss: 2.1266 - val_accuracy: 0.2828\nEpoch 13/20\n248/248 [==============================] - ETA: 0s - loss: 0.8641 - accuracy: 0.6773\nEpoch 13: val_loss did not improve from 1.44494\n248/248 [==============================] - 144s 580ms/step - loss: 0.8641 - accuracy: 0.6773 - val_loss: 2.0235 - val_accuracy: 0.4561\nEpoch 14/20\n248/248 [==============================] - ETA: 0s - loss: 0.8151 - accuracy: 0.6987\nEpoch 14: val_loss did not improve from 1.44494\n248/248 [==============================] - 143s 574ms/step - loss: 0.8151 - accuracy: 0.6987 - val_loss: 1.9952 - val_accuracy: 0.2641\nEpoch 15/20\n248/248 [==============================] - ETA: 0s - loss: 0.7730 - accuracy: 0.7159\nEpoch 15: val_loss did not improve from 1.44494\n248/248 [==============================] - 143s 578ms/step - loss: 0.7730 - accuracy: 0.7159 - val_loss: 2.0128 - val_accuracy: 0.2576\nEpoch 16/20\n248/248 [==============================] - ETA: 0s - loss: 0.7653 - accuracy: 0.7211\nEpoch 16: val_loss did not improve from 1.44494\n248/248 [==============================] - 143s 576ms/step - loss: 0.7653 - accuracy: 0.7211 - val_loss: 4.4743 - val_accuracy: 0.2162\nEpoch 17/20\n248/248 [==============================] - ETA: 0s - loss: 0.7366 - accuracy: 0.7388\nEpoch 17: val_loss did not improve from 1.44494\n248/248 [==============================] - 143s 574ms/step - loss: 0.7366 - accuracy: 0.7388 - val_loss: 2.7448 - val_accuracy: 0.2970\nEpoch 18/20\n248/248 [==============================] - ETA: 0s - loss: 0.7127 - accuracy: 0.7433\nEpoch 18: val_loss did not improve from 1.44494\n248/248 [==============================] - 143s 577ms/step - loss: 0.7127 - accuracy: 0.7433 - val_loss: 3.3032 - val_accuracy: 0.2091\nEpoch 19/20\n248/248 [==============================] - ETA: 0s - loss: 0.6785 - accuracy: 0.7572\nEpoch 19: val_loss did not improve from 1.44494\n248/248 [==============================] - 143s 575ms/step - loss: 0.6785 - accuracy: 0.7572 - val_loss: 4.1972 - val_accuracy: 0.2419\nEpoch 20/20\n248/248 [==============================] - ETA: 0s - loss: 0.6792 - accuracy: 0.7617\nEpoch 20: val_loss did not improve from 1.44494\n248/248 [==============================] - 142s 573ms/step - loss: 0.6792 - accuracy: 0.7617 - val_loss: 3.0885 - val_accuracy: 0.2020\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"4/4 [==============================] - 1s 111ms/step\n   image_id  label\n0      1266      2\n1      1862      2\n2       311      2\n3      3362      2\n4      3652      2\n..      ...    ...\n95     3813      3\n96      639      2\n97     3449      2\n98     1656      2\n99     1910      2\n\n[100 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(test)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T22:58:26.120164Z","iopub.execute_input":"2023-12-20T22:58:26.121013Z","iopub.status.idle":"2023-12-20T22:58:54.608582Z","shell.execute_reply.started":"2023-12-20T22:58:26.120976Z","shell.execute_reply":"2023-12-20T22:58:54.607610Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"62/62 [==============================] - 27s 442ms/step - loss: 0.9160 - accuracy: 0.6399\n","output_type":"stream"}]},{"cell_type":"code","source":"#1\ndef build_alexnet(input_shape=(224, 224, 3), num_classes=5):\n    model = Sequential()\n\n    # Convolutional Block 1\n    model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n    model.add(BatchNormalization())\n\n    # Convolutional Block 2\n    model.add(Conv2D(256, (5, 5), padding='same', activation='relu'))\n    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n    model.add(BatchNormalization())\n\n    # Convolutional Block 3\n    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n    model.add(MaxPooling2D((3, 3), strides=(2, 2)))\n    model.add(BatchNormalization())\n\n    # Fully Connected Layers\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1000, activation='relu')) \n    model.add(Dense(num_classes, activation='softmax')) \n\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model\n\ndef train_alexnet(model, train_data, test_data, epochs=100):\n    # Define early stopping callback\n    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True) #if no change in loss after 10 epochs\n\n    # Define model checkpoint callback to save the best weights\n    model_checkpoint = ModelCheckpoint('alexnet_best22.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min', verbose=1)\n\n    # Training\n   \n    model.fit(train_data, epochs=epochs, validation_data=test_data, callbacks=[early_stopping, model_checkpoint], verbose=1)\n \n\n    return model\n\ninput_shape = (224, 224, 3)\nnum_classes = 5\n\n# Build and train the model\nalexnet_model = build_alexnet(input_shape, num_classes)\ntrained_model = train_alexnet(alexnet_model,train,test, epochs=20)\nmodel=trained_model.save('model.h5')\n\n\n# Path to the test dataset\ntest_dataset_path = \"/kaggle/input/nn-dataset/dataset/dataset/test\"\n\ndef preprocess_test_dataset(test_dataset_path):\n    preprocessed_data = []\n    labels = []\n\n    test_images_paths = [os.path.join(test_dataset_path, filename) for filename in os.listdir(test_dataset_path) if\n                         filename.endswith(('.jpg', '.jpeg', '.png'))]\n\n    for image_path in test_images_paths:\n        image = cv2.imread(image_path)\n        if image is None:\n            print(f\"Error: Unable to read the image: {image_path}\")\n            continue\n\n        # Preprocess the resized image\n        preprocessed_image = preprocess_dataset(image)\n        preprocessed_data.append(preprocessed_image)\n\n        # Extract label without file extension\n        labels.append(os.path.splitext(os.path.basename(image_path))[0])\n\n    preprocessed_data = np.array(preprocessed_data)\n    if len(preprocessed_data.shape) == 3:\n        preprocessed_data = preprocessed_data.reshape((-1, 224, 224, 3))\n\n    return preprocessed_data, labels\n\n# Modified test_images function\ndef test_images(test_dataset_path, model):\n    preprocessed_data, labels = preprocess_test_dataset(test_dataset_path)\n\n    if preprocessed_data.shape[0] == 0:\n        print(\"No valid images in the test dataset.\")\n        return\n    #predictions according to our model\n    predictions = model.predict(preprocessed_data)\n    predicted_labels = np.argmax(predictions, axis=1) + 1\n\n    results = pd.DataFrame({'image_id': labels, 'label': predicted_labels})\n    print(results)\n\n    csv_file_path = 'predictions.csv'\n    results.to_csv(csv_file_path, index=False)\n\n# Load the trained model\n#trainedmodel = tf.keras.models.load_model('model.h5')\nalex_model = build_alexnet() \nalex_model.load_weights('/kaggle/working/alexnet_best22.h5')\n# Set the path to the test dataset\ntest_dataset_path = \"/kaggle/input/nn-dataset/dataset/dataset/test\"\n\n# Test the images and save the results to a CSV file\ntest_images(test_dataset_path, alex_model)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T23:32:09.302439Z","iopub.execute_input":"2023-12-19T23:32:09.302786Z","iopub.status.idle":"2023-12-20T00:12:35.301897Z","shell.execute_reply.started":"2023-12-19T23:32:09.302761Z","shell.execute_reply":"2023-12-20T00:12:35.300634Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Found 7920 images belonging to 5 classes.\nFound 1980 images belonging to 5 classes.\nEpoch 1/20\n248/248 [==============================] - ETA: 0s - loss: 1.6554 - accuracy: 0.3963\nEpoch 1: val_loss improved from inf to 1.98388, saving model to alexnet_best22.h5\n248/248 [==============================] - 124s 485ms/step - loss: 1.6554 - accuracy: 0.3963 - val_loss: 1.9839 - val_accuracy: 0.2813\nEpoch 2/20\n248/248 [==============================] - ETA: 0s - loss: 1.2310 - accuracy: 0.4761\nEpoch 2: val_loss improved from 1.98388 to 1.70369, saving model to alexnet_best22.h5\n248/248 [==============================] - 121s 486ms/step - loss: 1.2310 - accuracy: 0.4761 - val_loss: 1.7037 - val_accuracy: 0.3071\nEpoch 3/20\n248/248 [==============================] - ETA: 0s - loss: 1.1480 - accuracy: 0.5279\nEpoch 3: val_loss improved from 1.70369 to 1.26625, saving model to alexnet_best22.h5\n248/248 [==============================] - 121s 486ms/step - loss: 1.1480 - accuracy: 0.5279 - val_loss: 1.2662 - val_accuracy: 0.4520\nEpoch 4/20\n248/248 [==============================] - ETA: 0s - loss: 1.1074 - accuracy: 0.5539\nEpoch 4: val_loss did not improve from 1.26625\n248/248 [==============================] - 121s 489ms/step - loss: 1.1074 - accuracy: 0.5539 - val_loss: 4.1041 - val_accuracy: 0.2854\nEpoch 5/20\n248/248 [==============================] - ETA: 0s - loss: 1.0945 - accuracy: 0.5621\nEpoch 5: val_loss improved from 1.26625 to 1.20727, saving model to alexnet_best22.h5\n248/248 [==============================] - 124s 502ms/step - loss: 1.0945 - accuracy: 0.5621 - val_loss: 1.2073 - val_accuracy: 0.5035\nEpoch 6/20\n248/248 [==============================] - ETA: 0s - loss: 1.0619 - accuracy: 0.5804\nEpoch 6: val_loss improved from 1.20727 to 1.18877, saving model to alexnet_best22.h5\n248/248 [==============================] - 122s 493ms/step - loss: 1.0619 - accuracy: 0.5804 - val_loss: 1.1888 - val_accuracy: 0.4803\nEpoch 7/20\n248/248 [==============================] - ETA: 0s - loss: 1.0329 - accuracy: 0.5880\nEpoch 7: val_loss improved from 1.18877 to 1.15523, saving model to alexnet_best22.h5\n248/248 [==============================] - 121s 487ms/step - loss: 1.0329 - accuracy: 0.5880 - val_loss: 1.1552 - val_accuracy: 0.5202\nEpoch 8/20\n248/248 [==============================] - ETA: 0s - loss: 1.0064 - accuracy: 0.6076\nEpoch 8: val_loss did not improve from 1.15523\n248/248 [==============================] - 120s 484ms/step - loss: 1.0064 - accuracy: 0.6076 - val_loss: 1.5501 - val_accuracy: 0.3662\nEpoch 9/20\n248/248 [==============================] - ETA: 0s - loss: 0.9851 - accuracy: 0.6130\nEpoch 9: val_loss did not improve from 1.15523\n248/248 [==============================] - 120s 485ms/step - loss: 0.9851 - accuracy: 0.6130 - val_loss: 1.6412 - val_accuracy: 0.4182\nEpoch 10/20\n248/248 [==============================] - ETA: 0s - loss: 0.9592 - accuracy: 0.6232\nEpoch 10: val_loss improved from 1.15523 to 1.06417, saving model to alexnet_best22.h5\n248/248 [==============================] - 123s 495ms/step - loss: 0.9592 - accuracy: 0.6232 - val_loss: 1.0642 - val_accuracy: 0.5737\nEpoch 11/20\n248/248 [==============================] - ETA: 0s - loss: 0.9313 - accuracy: 0.6468\nEpoch 11: val_loss did not improve from 1.06417\n248/248 [==============================] - 120s 483ms/step - loss: 0.9313 - accuracy: 0.6468 - val_loss: 1.2761 - val_accuracy: 0.4788\nEpoch 12/20\n248/248 [==============================] - ETA: 0s - loss: 0.9226 - accuracy: 0.6444\nEpoch 12: val_loss did not improve from 1.06417\n248/248 [==============================] - 120s 485ms/step - loss: 0.9226 - accuracy: 0.6444 - val_loss: 1.0980 - val_accuracy: 0.5273\nEpoch 13/20\n248/248 [==============================] - ETA: 0s - loss: 0.8687 - accuracy: 0.6716\nEpoch 13: val_loss did not improve from 1.06417\n248/248 [==============================] - 120s 482ms/step - loss: 0.8687 - accuracy: 0.6716 - val_loss: 1.1212 - val_accuracy: 0.6141\nEpoch 14/20\n248/248 [==============================] - ETA: 0s - loss: 0.8886 - accuracy: 0.6634\nEpoch 14: val_loss did not improve from 1.06417\n248/248 [==============================] - 120s 482ms/step - loss: 0.8886 - accuracy: 0.6634 - val_loss: 1.1222 - val_accuracy: 0.5576\nEpoch 15/20\n248/248 [==============================] - ETA: 0s - loss: 0.9089 - accuracy: 0.6640\nEpoch 15: val_loss did not improve from 1.06417\n248/248 [==============================] - 120s 485ms/step - loss: 0.9089 - accuracy: 0.6640 - val_loss: 1.0922 - val_accuracy: 0.5773\nEpoch 16/20\n248/248 [==============================] - ETA: 0s - loss: 0.8887 - accuracy: 0.6631\nEpoch 16: val_loss did not improve from 1.06417\n248/248 [==============================] - 119s 481ms/step - loss: 0.8887 - accuracy: 0.6631 - val_loss: 1.2547 - val_accuracy: 0.5389\nEpoch 17/20\n248/248 [==============================] - ETA: 0s - loss: 0.8653 - accuracy: 0.6774\nEpoch 17: val_loss improved from 1.06417 to 1.01807, saving model to alexnet_best22.h5\n248/248 [==============================] - 121s 487ms/step - loss: 0.8653 - accuracy: 0.6774 - val_loss: 1.0181 - val_accuracy: 0.5854\nEpoch 18/20\n248/248 [==============================] - ETA: 0s - loss: 0.8504 - accuracy: 0.6862\nEpoch 18: val_loss did not improve from 1.01807\n248/248 [==============================] - 119s 480ms/step - loss: 0.8504 - accuracy: 0.6862 - val_loss: 1.3122 - val_accuracy: 0.5369\nEpoch 19/20\n248/248 [==============================] - ETA: 0s - loss: 0.8284 - accuracy: 0.6910\nEpoch 19: val_loss improved from 1.01807 to 0.96496, saving model to alexnet_best22.h5\n248/248 [==============================] - 122s 493ms/step - loss: 0.8284 - accuracy: 0.6910 - val_loss: 0.9650 - val_accuracy: 0.6379\nEpoch 20/20\n248/248 [==============================] - ETA: 0s - loss: 0.8188 - accuracy: 0.7015\nEpoch 20: val_loss did not improve from 0.96496\n248/248 [==============================] - 119s 480ms/step - loss: 0.8188 - accuracy: 0.7015 - val_loss: 1.1122 - val_accuracy: 0.5510\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"4/4 [==============================] - 1s 112ms/step\n   image_id  label\n0      1266      3\n1      1862      4\n2       311      2\n3      3362      2\n4      3652      3\n..      ...    ...\n95     3813      2\n96      639      3\n97     3449      2\n98     1656      2\n99     1910      4\n\n[100 rows x 2 columns]\n","output_type":"stream"}]}]}